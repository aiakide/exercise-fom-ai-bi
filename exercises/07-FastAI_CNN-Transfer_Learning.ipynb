{"cells":[{"cell_type":"markdown","metadata":{"id":"3kUNIl1lP5g8"},"source":["# Deep Learning Workshop"]},{"cell_type":"markdown","source":["Importing necessary libraries and modules from Fastai for working with deep learning tasks, particularly in computer vision."],"metadata":{"id":"c59lBIXN1as1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vc2osFtTVCTF"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["Downloads and extracts the Oxford-IIIT Pet dataset from Fastai's URLs.PETS source and sets the base directory to \"sample_data/oxford-iiit-pet\"."],"metadata":{"id":"7xQsE7qt1U8N"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ellZzmVJVgp0"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["Lists the contents of the data directory."],"metadata":{"id":"Wo-p9H2V1QbS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"c55-cLiuVpNX"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["Retrieves a list of image file paths within the \"images\" directory of the dataset."],"metadata":{"id":"NnKTKMy21Jgp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zW7t7_glV5cE"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["Defines a regular expression pattern to extract labels from the file names of images in the dataset. This pattern extracts the label before the underscore in the file names."],"metadata":{"id":"APFW5y0J1C-x"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sB0PzQa4WHDl"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["Constructs dataloaders for training and validation datasets from the file paths and label pattern defined earlier. It applies resizing transformation to images to have a size of 460 pixels (maintaining aspect ratio) before batching, and additional augmentations during training."],"metadata":{"id":"Y5bU1ccX05Q6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeZMjsKkXeLA"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["Displays a batch of images with their corresponding labels from the dataloaders."],"metadata":{"id":"RUUMtCl-0yne"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxeiiWvKXkbw"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["Initializes a learner object with a pretrained ResNet34 model architecture for transfer learning, using the dataloaders and specifying the error rate as the metric to monitor during training."],"metadata":{"id":"_mws8RhS0s_Y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Y8xeHyfYY5s"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["Runs the learning rate finder to identify an optimal learning rate for training. It suggests the minimum and steepest points on the learning rate curve."],"metadata":{"id":"RQTyw1gE0Tvq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDZfsE3-Y5bo"},"outputs":[],"source":[]},{"cell_type":"markdown","source":[" Fine-tunes the pre-trained model for 5 epochs with a learning rate of 35e-4.\n","\n"],"metadata":{"id":"M_IRzkpw0G2J"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YHQbsRMfY9Yb"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"D1dY1wg25Fr-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Displays the results of the trained model, showing predicted labels along with the corresponding ground truth labels."],"metadata":{"id":"WZH0GcQ0z-eA"}},{"cell_type":"code","source":[],"metadata":{"id":"eDKAvPD7jlw-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Generates an interpretation object from the trained learner, which is used to analyze model predictions."],"metadata":{"id":"jTgJUIxKz51y"}},{"cell_type":"code","source":[],"metadata":{"id":"MtbWwSDKjoFu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualizes the top loss images, i.e., the images where the model's predictions were most incorrect, along with their predicted and actual labels."],"metadata":{"id":"LwYBAePyz0pG"}},{"cell_type":"code","source":[],"metadata":{"id":"OVBJ-7HzjrR-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exports the trained model to a pickle file (\"/model.pkl\") for future use or deployment."],"metadata":{"id":"NC1zYA8Azrjg"}},{"cell_type":"code","source":[],"metadata":{"id":"_LUO5SKllNRK"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1ONUS09KH7Xa6KNSZk6CWuDjPeeLcuxnX","timestamp":1715015212460}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}