{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Jupyter Notebook: Einfaches CNN und AlexNet Implementierung mit CIFAR-10\n",
    "\n",
    "In diesem Notebook lernst du, wie du ein einfaches Convolutional Neural Network (CNN) auf dem CIFAR-10-Datensatz trainierst. Du wirst die Trainings- und Validierungsverluste nach jeder Epoche plotten und eine Heatmap-Funktion auf ein Beispielbild aus dem Validierungsdatensatz anwenden, um aktivierte Bildregionen zu visualisieren. Im zweiten Teil wirst du angeleitet, AlexNet anhand eines Bildes der Architektur selbst zu implementieren."
   ],
   "id": "47f789c2959a7cad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Datensatz vorbereiten\n",
    "\n",
    "Du wirst den CIFAR-10-Datensatz verwenden, der 60.000 32x32-Farbbilder in 10 Klassen enthält. Der Trainingsdatensatz wird in 80% Training und 20% Validierung aufgeteilt."
   ],
   "id": "75bd280b18ae30db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5865ce2c386e9f43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Einfaches CNN definieren\n",
    "\n",
    "Definiere ein einfaches CNN mit zwei Convolutional Layers und drei Fully Connected Layers."
   ],
   "id": "a15dbde29a173c23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5197064aeba268bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Training des Modells\n",
    "\n",
    "Trainiere das Modell mit dem Adam-Optimizer und der Cross-Entropy Loss-Funktion. Nach dem Training werden die Verluste geplottet."
   ],
   "id": "afeb6fd8221e89d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bd580aae07f2ed77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss', marker='o')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Trainings- und Validierungsverluste')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "5a1186b1dfeec1ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "49e5254cabfd0439",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Evaluation auf Testdatensatz\n",
    "\n",
    "Evaluiere das Modell auf dem Testdatensatz, um die endgültige Leistung zu überprüfen."
   ],
   "id": "50bd9ca4fcbfa007"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b1f87768e209f096",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. AlexNet implementieren\n",
    "\n",
    "In diesem Abschnitt wirst du AlexNet anhand eines Bildes der Architektur implementieren. Deine Aufgabe ist es, die Architektur in PyTorch zu programmieren, indem du die Schichten und Verbindungen aus dem Bild nachbaust.\n",
    "\n",
    "Bild der AlexNet-Architektur\n",
    "\n",
    "\n",
    "\n",
    "### Anleitung zur Implementierung\n",
    "\n",
    "Um AlexNet zu implementieren, folge diesen Schritten:\n",
    "**1. Analysiere das Bild**:\n",
    "_ Schaue dir die Schichten der Architektur genau an. Beachte die Anzahl der Convolutional Layers, Pooling Layers und Fully Connected Layers.\n",
    "- Identifiziere die Anzahl der Filter, Kernel-Größen, Strides, Padding-Werte und Aktivierungsfunktionen (z.B. ReLU).\n",
    "- Achte auf Dropout-Schichten und die Größe der Fully Connected Layers.\n",
    "\n",
    "**2. Erstelle das Modell in PyTorch**:\n",
    "- Definiere eine Klasse AlexNet, die von nn.Module erbt\n",
    "- Implementiere die Convolutional Layers mit nn.Conv2d, Pooling Layers mit nn.MaxPool2d und Fully Connected Layers mit nn.Linear.\n",
    "- Füge ReLU-Aktivierungen (F.relu oder nn.ReLU) und Dropout (nn.Dropout) hinzu, wie im Bild angegeben.\n",
    "- Stelle sicher, dass die Eingabegröße (32x32 für CIFAR-10) mit der Architektur kompatibel ist. Du musst möglicherweise Kernel-Größen oder Strides anpassen, da AlexNet ursprünglich für 224x224-Bilder entwickelt wurde.\n",
    "\n",
    "**3. Forward-Pass**:\n",
    "- Implementiere die forward-Methode, die die Eingabe durch die Schichten führt.\n",
    "- Achte darauf, die Dimensionen nach den Convolutional Layers zu flatten (z.B. mit x.view), bevor du die Fully Connected Layers anwendest.\n",
    "\n",
    "**4. Training**:\n",
    "- Trainiere dein AlexNet-Modell ähnlich wie das einfache CNN oben. Verwende den gleichen trainloader, valloader und testloader, die Adam-Optimizer und Cross-Entropy Loss.\n",
    "- Du kannst die gleichen Funktionen (validate_model, plot_losses, create_heatmap) wiederverwenden, um Verluste zu plotten und Heatmaps zu erstellen.\n",
    "\n",
    "### Tipps\n",
    "- **Dimensionen überprüfen**: Berechne die Ausgabegrößen jeder Schicht, um sicherzustellen, dass die Fully Connected Layers die richtige Eingabegröße erhalten. Für CIFAR-10 (32x32) musst du die Parameter anpassen, da AlexNet für größere Bilder ausgelegt ist.\n",
    "- **Debugging**: Teste dein Modell mit einem einzelnen Batch, um sicherzustellen, dass die Dimensionen korrekt sind (z.B. output = model(torch.randn(1, 3, 32, 32).to(device))).\n",
    "- **Anpassungen**: Falls die ursprüngliche AlexNet-Architektur zu komplex ist, kannst du die Anzahl der Filter oder Schichten reduzieren, um sie für CIFAR-10 zu optimieren.\n",
    "\n",
    "### Beispiel für den Anfang\n",
    "\n",
    "Hier ist ein Gerüst, um dir den Einstieg zu erleichtern, ohne die vollständige Implementierung zu verraten:"
   ],
   "id": "bdd493f26e2697e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        # Definiere hier die Schichten basierend auf dem Bild\n",
    "        self.features = nn.Sequential(\n",
    "            # Beispiel: nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            # Füge weitere Schichten hinzu\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Beispiel: nn.Linear(in_features, out_features),\n",
    "            # Füge weitere Schichten hinzu\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Implementiere den Forward-Pass\n",
    "        x = self.features(x)\n",
    "        # Flattening\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Modell initialisieren und auf GPU verschieben\n",
    "model = AlexNet().to(device)"
   ],
   "id": "12dcc31e6949f45d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Aufgabe: Fülle die features und classifier Abschnitte basierend auf dem Bild der Architektur aus. Trainiere das Modell anschließend mit der gleichen Trainingsschleife wie beim einfachen CNN und überprüfe die Leistung auf dem Testdatensatz.",
   "id": "4913b18e89809e00"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
